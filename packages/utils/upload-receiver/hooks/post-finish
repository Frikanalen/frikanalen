#!/usr/bin/env python3
""" This script is invoked by tusd upon successful reception of a complete file.

"""
import json
import sys
import os
from loguru import logger
# noinspection PyPackageRequirements
from kafka import KafkaProducer

KAFKA_SERVER = os.environ.get('KAFKA_SERVER', None)


if KAFKA_SERVER is None:
    KAFKA_SERVER = 'kafka-service.kafka:9092'
    logger.warning(f"KAFKA_SERVER environment variable not set; defaulting to {KAFKA_SERVER}")


def read_upload_status():
    """ Reads the JSON data from tusd, and returns a tuple of numeric video ID, original
    file name, and S3 key.

    Example JSON data:

    "Upload": {
        "ID": "9a1a39798141223fb20f133f2bc58535+2~Qe1PIASV0XqmPse9fP-oq6PMzy-ZvdD",
        "IsFinal": false,
        "IsPartial": false,
        "MetaData": {
            "origFileName": "IMG_1133.MOV",
            "uploadToken": "6182701c94024dd4ac75866ed5071bf1",
            "videoID": "626739"
        },
        "Offset": 9844291,
        "PartialUploads": null,
        "Size": 9844291,
        "SizeIsDeferred": false,
        "Storage": {
            "Bucket": "incoming",
            "Key": "9a1a39798141223fb20f133f2bc58535",
            "Type": "s3store"
        }
    }
    """
    s = json.load(sys.stdin)["Upload"]
    return (s["MetaData"]["videoID"], s["MetaData"]["origFileName"],
            s["Storage"]["Key"])


if __name__ == '__main__':
    video_id, orig_filename, s3_key = read_upload_status()
    event_data = {
        "version": 1,
        "video_id": int(video_id),
        "orig_filename": orig_filename,
        "s3_key": s3_key
    }

    p = KafkaProducer(
        bootstrap_servers=KAFKA_SERVER,
        value_serializer=lambda x: json.dumps(x).encode('utf-8'),
    )

    future = p.send('new-video-uploaded', event_data)
    print(json.dumps(event_data, indent=2), file=sys.stderr)
    print(future.get(timeout=60), file=sys.stderr)
